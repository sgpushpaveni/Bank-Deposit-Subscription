{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9388b669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\python\\lib\\site-packages (from lightgbm) (2.2.5)\n",
      "Requirement already satisfied: scipy in d:\\python\\lib\\site-packages (from lightgbm) (1.15.3)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 11.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f4a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0deb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def build_preprocessor():\n",
    "    # Ordinal mapping for education\n",
    "    education_order = ['unknown', 'primary', 'secondary', 'tertiary']\n",
    "    ordinal_cols = ['education']\n",
    "    nominal_cols = ['job', 'marital', 'contact', 'month', 'poutcome']\n",
    "    binary_cols = ['default', 'housing', 'loan']\n",
    "    numeric_cols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous', 'day']\n",
    "\n",
    "    ordinal_pipe = Pipeline([\n",
    "        ('ord', OrdinalEncoder(categories=[education_order], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "    nominal_pipe = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    binary_pipe = Pipeline([\n",
    "        ('onehot', OneHotEncoder(drop='if_binary'))\n",
    "    ])\n",
    "    numeric_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('ord', ordinal_pipe, ordinal_cols),\n",
    "        ('nom', nominal_pipe, nominal_cols),\n",
    "        ('bin', binary_pipe, binary_cols),\n",
    "        ('num', numeric_pipe, numeric_cols)\n",
    "    ])\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def preprocess(df, preprocessor=None, fit=True):\n",
    "    X = df.drop(['y', 'id'], axis=1)\n",
    "    y = df['y']\n",
    "    # Optionally create interaction features here (example)\n",
    "    X['balance_x_duration'] = X['balance'] * X['duration']\n",
    "    X['age_x_education'] = X['age'] * X['education'].map({'unknown':0, 'primary':1, 'secondary':2, 'tertiary':3})\n",
    "    if fit:\n",
    "        X_processed = preprocessor.fit_transform(X)\n",
    "    else:\n",
    "        X_processed = preprocessor.transform(X)\n",
    "    return X_processed, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3070c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"LightGBM\": LGBMClassifier(),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"NaiveBayes\": GaussianNB(),\n",
    "        \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(64,32), max_iter=500)\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def train_and_evaluate(model_name,model, X, y):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    results[model_name] = {\n",
    "        \"model\": model,\n",
    "        \"score\": model.score(X_test, y_test)\n",
    "    }\n",
    "    joblib.dump(model, f\"models_new/{model_name}.joblib\")\n",
    "    return results, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a245d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor saved to models/preprocessor.joblib\n",
      "Logistic Regression Score: 0.91506\n",
      "Random Forest Score: 0.9305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = load_data(r\"D:\\GUVI-Projects\\Capstone\\Project1_Bank\\code-models\\data\\train.csv\")\n",
    "preprocessor = build_preprocessor()\n",
    "X, y = preprocess(df, preprocessor)\n",
    "\n",
    "# Save preprocessor object for later use (e.g., in Streamlit/app)\n",
    "joblib.dump(preprocessor, \"models_new/preprocessor.joblib\")\n",
    "print(\"Preprocessor saved to models_new/preprocessor.joblib\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Score:\", lr.score(X_test, y_test))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Random Forest Score:\", rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': 0.91506}\n",
      "{'RandomForest': 0.93092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:19:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XGBoost': 0.9337733333333333}\n",
      "[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n",
      "[LightGBM] [Info] Start training from score -1.986289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LightGBM': 0.93342}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = get_models()\n",
    "model_results = {}\n",
    "for name, model in models.items():\n",
    "    results, X_test, y_test = train_and_evaluate(name, model, X, y)\n",
    "    print({k: v[\"score\"] for k,v in results.items()})\n",
    "    model_results = results\n",
    "\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509e9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(r\"D:\\GUVI-Projects\\Capstone\\Project1_Bank\\code-models\\data\\train.csv\")\n",
    "preprocessor = build_preprocessor()\n",
    "X, y = preprocess(df, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67b3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NaiveBayes': 0.8599933333333334}\n",
      "{'MLPClassifier': 0.9316133333333333}\n",
      "{'MLPClassifier': {'model': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500), 'score': 0.9316133333333333}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"NaiveBayes\": GaussianNB(),\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(64,32), max_iter=500)\n",
    "}\n",
    "model_results = {}\n",
    "for name, model in models.items():\n",
    "    results, X_test, y_test = train_and_evaluate(name, model, X, y)\n",
    "    print({k: v[\"score\"] for k,v in results.items()})\n",
    "    model_results = results\n",
    "\n",
    "print(model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
